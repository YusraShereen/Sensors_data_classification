{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFInT4E4yoWR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBSo0uEzyxI-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import pywt\n",
        "from PIL import Image  \n",
        "import PIL  \n",
        "from skimage.io import imsave, imread"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbnKRL7x_8du"
      },
      "outputs": [],
      "source": [
        "from dask import bag, diagnostics \n",
        "#import hvplot.pandas\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xppL-beI7JEg"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "import cv2\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, zero_one_loss, classification_report\n",
        "import seaborn as sns\n",
        "from tensorflow import keras\n",
        "import matplotlib.cm as cm\n",
        "from IPython.display import Image, display\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from keras.layers import Input\n",
        "from keras.layers import Convolution2D , concatenate ,Conv2D,Dense\n",
        "from keras.layers import Activation,Dropout, GlobalAveragePooling2D,MaxPooling2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam ,SGD,RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4_zKnFfMK7o"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from keras.layers import MaxPool2D, concatenate, AveragePooling2D\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import h5py\n",
        "from keras.layers import Concatenate\n",
        "import keras.backend as K\n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import LearningRateScheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMU1XDQhj8YM"
      },
      "outputs": [],
      "source": [
        "from glob import glob \n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNEnTVDP1BYN"
      },
      "outputs": [],
      "source": [
        "base_path = '/content/drive/MyDrive/Sem 2/CV/Sensors_data/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCk0FvCiR9mW"
      },
      "source": [
        "# **Humidity Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwUMZQflSD4A"
      },
      "outputs": [],
      "source": [
        "data_path = base_path + 'Humidity/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VlBLF-TDrJ6",
        "outputId": "5d7901f1-03ed-471d-aba4-cace1482dd10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Winter', 'Summer', 'Spring', 'Autumn']\n"
          ]
        }
      ],
      "source": [
        "classes = list(os.listdir(data_path))\n",
        "print(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFYKn_ec-Gtk"
      },
      "outputs": [],
      "source": [
        "import PIL.Image\n",
        "\n",
        "def cs_images(path,img_shape, classes):\n",
        "    imag = []\n",
        "    label = []\n",
        "    for i in classes:\n",
        "        l1 = os.listdir(path+'/'+i)\n",
        "        for j in l1:\n",
        "            img = PIL.Image.open(path+'/'+i+'/'+j)\n",
        "            img = img.resize(size = (img_shape[0], img_shape[0]))\n",
        "            #img = img.convert('L')\n",
        "            #img = img.reshape(50,50,1)\n",
        "            #img = img.flatten()\n",
        "            img = cv2.imread(path+'/'+i+'/'+j)\n",
        "            img = cv2.resize(img,(img_shape[0],img_shape[1]),3)\n",
        "            #img = np.array(img).reshape(img_shape)\n",
        "            #img = img.reshape(img_shape)\n",
        "            imag.append(img)\n",
        "            label.append(classes.index(i))\n",
        "            del(img)\n",
        "    # %matplotlib inline \n",
        "    # plt.figure(figsize=(10, 10))\n",
        "    # for i in range(20):\n",
        "    #     plt.subplot(5,4,i+1)\n",
        "    #     plt.imshow(imag[i])\n",
        "    #     plt.axis('off')\n",
        "    # plt.show()\n",
        "    return np.array(imag),label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JiIMIjrCevG"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-Eil-C_-LMy"
      },
      "outputs": [],
      "source": [
        "x,y = cs_images(data_path,(IMG_SIZE, IMG_SIZE, 1),classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8Gd2-guO4AR"
      },
      "outputs": [],
      "source": [
        "y = pd.Series(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyQy4Fl6ASJA"
      },
      "outputs": [],
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,\n",
        "                                                 test_size = 0.2,\n",
        "                                                 random_state = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUgdGnK-AaKi",
        "outputId": "6d4cc896-cdd6-4a0b-c80d-7036c3db8b16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(273, 224, 224, 3)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9CADqJJAexM",
        "outputId": "3eff296a-fe7e-4e53-f41f-7f165f243d44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "85     0\n",
              "73     0\n",
              "287    3\n",
              "304    3\n",
              "165    1\n",
              "329    3\n",
              "167    1\n",
              "14     0\n",
              "244    2\n",
              "105    1\n",
              "dtype: int64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUmBn720AmE3",
        "outputId": "fd8940c5-9a04-4529-afe9-c7b5a572766c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(273,)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3x7hnsmRApXS",
        "outputId": "e2ccfd4a-bd96-4c77-dc0e-71498d545bc1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(69, 224, 224, 3)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZvJbvOlAva-",
        "outputId": "90a8f8b7-eb2c-4bbc-c17d-634839bc471e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(69,)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ws2Smm0lbuJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "IMAGE_SIZE = [224, 224] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm79PSY4nW10",
        "outputId": "48fb36e6-73af-45da-f335-d28bf8533eca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 1s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 30)                752670    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 124       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,777,178\n",
            "Trainable params: 752,794\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Create a VGG16 model, and removing the last layer that is classifying 1000 images. This will be replaced with images classes we have. \n",
        "#vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False) #Training with Imagenet weights\n",
        "# Use this line for VGG19 network. Create a VGG19 model, and removing the last layer that is classifying 1000 images. This will be replaced with images classes we have. \n",
        "\n",
        "\n",
        "vgg = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
        "# This sets the base that the layers are not trainable. If we'd want to train the layers with custom data, these two lines can be ommitted. \n",
        "for layer in vgg.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "x = Flatten()(vgg.output) #Output obtained on vgg16 is now flattened. \n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(30, activation='relu')(x)\n",
        "prediction = Dense(len(classes), activation='softmax')(x) # We have 5 classes, and so, the prediction is being done on len(folders) - 5 classes\n",
        "#Creating model object \n",
        "model = Model(inputs=vgg.input, outputs=prediction)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_0UdIPiDVTW"
      },
      "source": [
        "### SGDM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3TbPXbvZzjT"
      },
      "outputs": [],
      "source": [
        "opt = tf.keras.optimizers.Adagrad(\n",
        "    learning_rate= 0.1,\n",
        "    initial_accumulator_value=0.1,\n",
        "    epsilon=1e-07,\n",
        "    weight_decay=None,\n",
        "    clipnorm=None,\n",
        "    clipvalue=None,\n",
        "    global_clipnorm=None,\n",
        "    use_ema=False,\n",
        "    ema_momentum=0.99,\n",
        "    ema_overwrite_frequency=None,\n",
        "    jit_compile=True,\n",
        "    name=\"Adagrad\",\n",
        "    #**kwargs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fqu6oC3xoyj6"
      },
      "outputs": [],
      "source": [
        "#opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "#opt = tf.keras.optimizers.experimental.SGD(0.01, momentum=0.9)\n",
        "#Compile the model \n",
        "model.compile(loss='sparse_categorical_crossentropy', \n",
        "              optimizer= opt, \n",
        "              metrics=['accuracy']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlZhekEPUVJE"
      },
      "outputs": [],
      "source": [
        "es = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        # Stop training when `val_loss` is no longer improving\n",
        "        monitor='val_loss',\n",
        "        # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
        "        min_delta=1e-3,\n",
        "        # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
        "        patience=25,\n",
        "        verbose=1)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WaljovwUC-L",
        "outputId": "c7d04313-6f3e-401c-b34c-b83a80a9e218"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "9/9 [==============================] - 304s 34s/step - loss: 321.2348 - accuracy: 0.2930 - val_loss: 1.3872 - val_accuracy: 0.2464\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 303s 35s/step - loss: 1.3752 - accuracy: 0.3040 - val_loss: 1.3894 - val_accuracy: 0.2464\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 297s 34s/step - loss: 1.3651 - accuracy: 0.3040 - val_loss: 1.3905 - val_accuracy: 0.2464\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 301s 34s/step - loss: 1.3677 - accuracy: 0.3040 - val_loss: 1.3916 - val_accuracy: 0.2464\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 296s 34s/step - loss: 1.3675 - accuracy: 0.3040 - val_loss: 1.3922 - val_accuracy: 0.2464\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 296s 34s/step - loss: 1.3675 - accuracy: 0.3040 - val_loss: 1.3935 - val_accuracy: 0.2464\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 269s 31s/step - loss: 1.3664 - accuracy: 0.2747 - val_loss: 1.3956 - val_accuracy: 0.2464\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 268s 30s/step - loss: 1.3658 - accuracy: 0.3040 - val_loss: 1.3962 - val_accuracy: 0.2464\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 296s 34s/step - loss: 1.3656 - accuracy: 0.3040 - val_loss: 1.3962 - val_accuracy: 0.2464\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 296s 34s/step - loss: 1.3656 - accuracy: 0.3040 - val_loss: 1.3964 - val_accuracy: 0.2464\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 278s 31s/step - loss: 1.3659 - accuracy: 0.3040 - val_loss: 1.3965 - val_accuracy: 0.2464\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 297s 34s/step - loss: 1.3660 - accuracy: 0.3040 - val_loss: 1.3974 - val_accuracy: 0.2464\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 296s 34s/step - loss: 1.3656 - accuracy: 0.3040 - val_loss: 1.3970 - val_accuracy: 0.2464\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 296s 34s/step - loss: 1.3650 - accuracy: 0.3040 - val_loss: 1.3974 - val_accuracy: 0.2464\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 296s 34s/step - loss: 1.3650 - accuracy: 0.3040 - val_loss: 1.3984 - val_accuracy: 0.2464\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 295s 34s/step - loss: 1.3656 - accuracy: 0.3040 - val_loss: 1.3983 - val_accuracy: 0.2464\n",
            "Epoch 17/200\n",
            "9/9 [==============================] - 296s 34s/step - loss: 1.3661 - accuracy: 0.3040 - val_loss: 1.3979 - val_accuracy: 0.2464\n",
            "Epoch 18/200\n",
            "9/9 [==============================] - 295s 34s/step - loss: 1.3651 - accuracy: 0.3040 - val_loss: 1.3983 - val_accuracy: 0.2464\n",
            "Epoch 19/200\n",
            "9/9 [==============================] - 296s 34s/step - loss: 1.3654 - accuracy: 0.3040 - val_loss: 1.3990 - val_accuracy: 0.2464\n",
            "Epoch 20/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3650 - accuracy: 0.3040 - val_loss: 1.3988 - val_accuracy: 0.2464\n",
            "Epoch 21/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3652 - accuracy: 0.3040 - val_loss: 1.3988 - val_accuracy: 0.2464\n",
            "Epoch 22/200\n",
            "9/9 [==============================] - 289s 33s/step - loss: 1.3649 - accuracy: 0.3040 - val_loss: 1.3986 - val_accuracy: 0.2464\n",
            "Epoch 23/200\n",
            "9/9 [==============================] - 289s 33s/step - loss: 1.3656 - accuracy: 0.2674 - val_loss: 1.3997 - val_accuracy: 0.2464\n",
            "Epoch 24/200\n",
            "9/9 [==============================] - 289s 33s/step - loss: 1.3654 - accuracy: 0.3040 - val_loss: 1.3995 - val_accuracy: 0.2464\n",
            "Epoch 25/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3653 - accuracy: 0.3040 - val_loss: 1.3992 - val_accuracy: 0.2464\n",
            "Epoch 26/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3654 - accuracy: 0.3040 - val_loss: 1.3983 - val_accuracy: 0.2464\n",
            "Epoch 27/200\n",
            "9/9 [==============================] - 261s 30s/step - loss: 1.3650 - accuracy: 0.3040 - val_loss: 1.3982 - val_accuracy: 0.2464\n",
            "Epoch 28/200\n",
            "9/9 [==============================] - 288s 33s/step - loss: 1.3651 - accuracy: 0.3040 - val_loss: 1.3980 - val_accuracy: 0.2464\n",
            "Epoch 29/200\n",
            "9/9 [==============================] - 259s 29s/step - loss: 1.3649 - accuracy: 0.3040 - val_loss: 1.3983 - val_accuracy: 0.2464\n",
            "Epoch 30/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3651 - accuracy: 0.2747 - val_loss: 1.3985 - val_accuracy: 0.2464\n",
            "Epoch 31/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3648 - accuracy: 0.3040 - val_loss: 1.3982 - val_accuracy: 0.2464\n",
            "Epoch 32/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3652 - accuracy: 0.3040 - val_loss: 1.3984 - val_accuracy: 0.2464\n",
            "Epoch 33/200\n",
            "9/9 [==============================] - 289s 33s/step - loss: 1.3650 - accuracy: 0.3040 - val_loss: 1.3982 - val_accuracy: 0.2464\n",
            "Epoch 34/200\n",
            "9/9 [==============================] - 291s 33s/step - loss: 1.3651 - accuracy: 0.3040 - val_loss: 1.3985 - val_accuracy: 0.2464\n",
            "Epoch 35/200\n",
            "9/9 [==============================] - 260s 29s/step - loss: 1.3650 - accuracy: 0.3040 - val_loss: 1.3986 - val_accuracy: 0.2464\n",
            "Epoch 36/200\n",
            "9/9 [==============================] - 259s 29s/step - loss: 1.3649 - accuracy: 0.2894 - val_loss: 1.3988 - val_accuracy: 0.2464\n",
            "Epoch 37/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3609 - accuracy: 0.2894 - val_loss: 1.3989 - val_accuracy: 0.2464\n",
            "Epoch 38/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3651 - accuracy: 0.3040 - val_loss: 1.3986 - val_accuracy: 0.2464\n",
            "Epoch 39/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3650 - accuracy: 0.3040 - val_loss: 1.3982 - val_accuracy: 0.2464\n",
            "Epoch 40/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3651 - accuracy: 0.3040 - val_loss: 1.3981 - val_accuracy: 0.2464\n",
            "Epoch 41/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3652 - accuracy: 0.3040 - val_loss: 1.3980 - val_accuracy: 0.2464\n",
            "Epoch 42/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3654 - accuracy: 0.3040 - val_loss: 1.3977 - val_accuracy: 0.2464\n",
            "Epoch 43/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3649 - accuracy: 0.3040 - val_loss: 1.3973 - val_accuracy: 0.2464\n",
            "Epoch 44/200\n",
            "9/9 [==============================] - 289s 33s/step - loss: 1.3650 - accuracy: 0.3040 - val_loss: 1.3981 - val_accuracy: 0.2464\n",
            "Epoch 45/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3654 - accuracy: 0.2747 - val_loss: 1.3988 - val_accuracy: 0.2464\n",
            "Epoch 46/200\n",
            "9/9 [==============================] - 289s 33s/step - loss: 1.3652 - accuracy: 0.3040 - val_loss: 1.3989 - val_accuracy: 0.2464\n",
            "Epoch 47/200\n",
            "9/9 [==============================] - 289s 33s/step - loss: 1.3650 - accuracy: 0.3040 - val_loss: 1.3986 - val_accuracy: 0.2464\n",
            "Epoch 48/200\n",
            "9/9 [==============================] - 289s 33s/step - loss: 1.3652 - accuracy: 0.3040 - val_loss: 1.3988 - val_accuracy: 0.2464\n",
            "Epoch 49/200\n",
            "9/9 [==============================] - 289s 33s/step - loss: 1.3650 - accuracy: 0.3040 - val_loss: 1.3985 - val_accuracy: 0.2464\n",
            "Epoch 50/200\n",
            "9/9 [==============================] - 291s 33s/step - loss: 1.3651 - accuracy: 0.3040 - val_loss: 1.3988 - val_accuracy: 0.2464\n",
            "Epoch 51/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3654 - accuracy: 0.3040 - val_loss: 1.3988 - val_accuracy: 0.2464\n",
            "Epoch 52/200\n",
            "9/9 [==============================] - 261s 30s/step - loss: 1.3651 - accuracy: 0.3040 - val_loss: 1.3987 - val_accuracy: 0.2464\n",
            "Epoch 53/200\n",
            "9/9 [==============================] - 295s 34s/step - loss: 1.3649 - accuracy: 0.3040 - val_loss: 1.3987 - val_accuracy: 0.2464\n",
            "Epoch 54/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3652 - accuracy: 0.3040 - val_loss: 1.3987 - val_accuracy: 0.2464\n",
            "Epoch 55/200\n",
            "9/9 [==============================] - 260s 29s/step - loss: 1.3649 - accuracy: 0.3040 - val_loss: 1.3980 - val_accuracy: 0.2464\n",
            "Epoch 56/200\n",
            "9/9 [==============================] - 289s 33s/step - loss: 1.3651 - accuracy: 0.3040 - val_loss: 1.3976 - val_accuracy: 0.2464\n",
            "Epoch 57/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3650 - accuracy: 0.3040 - val_loss: 1.3979 - val_accuracy: 0.2464\n",
            "Epoch 58/200\n",
            "9/9 [==============================] - 288s 33s/step - loss: 1.3650 - accuracy: 0.3040 - val_loss: 1.3979 - val_accuracy: 0.2464\n",
            "Epoch 59/200\n",
            "9/9 [==============================] - 288s 33s/step - loss: 1.3649 - accuracy: 0.3040 - val_loss: 1.3979 - val_accuracy: 0.2464\n",
            "Epoch 60/200\n",
            "9/9 [==============================] - 260s 30s/step - loss: 1.3654 - accuracy: 0.3040 - val_loss: 1.3984 - val_accuracy: 0.2464\n",
            "Epoch 61/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3649 - accuracy: 0.2747 - val_loss: 1.3981 - val_accuracy: 0.2464\n",
            "Epoch 62/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3653 - accuracy: 0.3040 - val_loss: 1.3984 - val_accuracy: 0.2464\n",
            "Epoch 63/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3650 - accuracy: 0.3040 - val_loss: 1.3986 - val_accuracy: 0.2464\n",
            "Epoch 64/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3651 - accuracy: 0.2747 - val_loss: 1.3985 - val_accuracy: 0.2464\n",
            "Epoch 65/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3651 - accuracy: 0.2674 - val_loss: 1.3984 - val_accuracy: 0.2464\n",
            "Epoch 66/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3649 - accuracy: 0.3040 - val_loss: 1.3983 - val_accuracy: 0.2464\n",
            "Epoch 67/200\n",
            "9/9 [==============================] - 289s 33s/step - loss: 1.3649 - accuracy: 0.3040 - val_loss: 1.3983 - val_accuracy: 0.2464\n",
            "Epoch 68/200\n",
            "9/9 [==============================] - 259s 29s/step - loss: 1.3650 - accuracy: 0.3040 - val_loss: 1.3983 - val_accuracy: 0.2464\n",
            "Epoch 69/200\n",
            "9/9 [==============================] - 260s 29s/step - loss: 1.3648 - accuracy: 0.3040 - val_loss: 1.3984 - val_accuracy: 0.2464\n",
            "Epoch 70/200\n",
            "9/9 [==============================] - 258s 29s/step - loss: 1.3652 - accuracy: 0.3040 - val_loss: 1.3988 - val_accuracy: 0.2464\n",
            "Epoch 71/200\n",
            "9/9 [==============================] - 260s 29s/step - loss: 1.3650 - accuracy: 0.3040 - val_loss: 1.3989 - val_accuracy: 0.2464\n",
            "Epoch 72/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3651 - accuracy: 0.3040 - val_loss: 1.3990 - val_accuracy: 0.2464\n",
            "Epoch 73/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3648 - accuracy: 0.3040 - val_loss: 1.3990 - val_accuracy: 0.2464\n",
            "Epoch 74/200\n",
            "9/9 [==============================] - 289s 33s/step - loss: 1.3649 - accuracy: 0.3040 - val_loss: 1.3986 - val_accuracy: 0.2464\n",
            "Epoch 75/200\n",
            "9/9 [==============================] - 290s 33s/step - loss: 1.3650 - accuracy: 0.3040 - val_loss: 1.3986 - val_accuracy: 0.2464\n",
            "Epoch 76/200\n",
            "5/9 [===============>..............] - ETA: 1:37 - loss: 1.3649 - accuracy: 0.2937"
          ]
        }
      ],
      "source": [
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    epochs= 200,\n",
        "                    validation_data = (x_test,y_test),\n",
        "                    verbose = 1,\n",
        "                    #callbacks = [es],\n",
        "                    batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnDsIwOhpAof"
      },
      "outputs": [],
      "source": [
        "# loss\n",
        "plt.plot(history.history['loss'], label='train loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        " \n",
        " # accuracies\n",
        "plt.plot(history.history['accuracy'], label='train acc')\n",
        "plt.plot(history.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XIVVv_XpHwy"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model.save('/content/drive/MyDrive/Sem 2/CV/Saved_models/sensors_humidity_vgg19.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__qHq1VsqC1T"
      },
      "outputs": [],
      "source": [
        "y_pred = np.argmax(model.predict(x_test),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVG84JEUE69y"
      },
      "outputs": [],
      "source": [
        "y_pred[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWInly6bE-97"
      },
      "outputs": [],
      "source": [
        "list(y_test[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sn7jyUmLFdE7"
      },
      "outputs": [],
      "source": [
        "model.evaluate(x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRfgjXatXuWg"
      },
      "outputs": [],
      "source": [
        "print(classes)\n",
        "# print(y_test[:25], '\\n')\n",
        "# print(y_pred[:25], '\\n')\n",
        "\n",
        "# predict = []\n",
        "# for i in range(3000): #len(y_pred)\n",
        "#   predict.append(np.argmax(y_pred[i]))\n",
        "\n",
        "# print(predict[:25], '\\n')\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm, '\\n')\n",
        "\n",
        "zol = zero_one_loss(y_test, y_pred, normalize = False)\n",
        "print(zol, '\\n')\n",
        "\n",
        "cr = classification_report(y_test, y_pred)\n",
        "print(cr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uNTPvNTXuXE"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (5,5))\n",
        "ConfusionMatrixDisplay(cm).plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vG996AhhtzUQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}